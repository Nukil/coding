#spark config
#每个partition 每秒从topic 每个partition最多消费的数据条数
spark.streaming.kafka.maxRatePerPartition=50
#是否开启背压调节[true,false]
spark.streaming.backpressure.enabled=true
#数据消费间隔 单位:s/秒
batchDuration=2
spark.streaming.kafka.consumer.poll.ms=1000
spark.streaming.stopGracefullyOnShutdown=true
sparkStr= --master yarn-cluster --class com.netposa.poseidon.fakecardetect.main.FakeCarDetectMainServer  --num-executors 4    --conf spark.yarn.maxAppAttempts=4     --conf spark.yarn.am.attemptFailuresValidityInterval=1h     --conf spark.yarn.max.executor.failures=16    --conf spark.yarn.executor.failuresValidityInterval=1h     --conf spark.task.maxFailures=8 --name FakeCarDetectMainServer --executor-memory 5g --driver-memory 5g 
is.start.from.checkpoint=false